name: Karachi AQI CI/CD Pipeline

# Automated CI/CD pipeline for Karachi AQI prediction system
# - Data collection: Every hour
# - Model training: Daily at 2 AM UTC
# - Manual trigger: Available via workflow_dispatch
# This workflow processes raw data, trains models, and deploys.

on:
  schedule:
    # Run data collection every hour
    - cron: '0 * * * *'
    # Run model training daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      run_data_collection:
        description: 'Run Data Collection Job'
        required: true
        type: boolean
        default: true
      run_model_training:
        description: 'Run Model Training Job'
        required: true
        type: boolean
        default: false
  workflow_call:
    secrets:
      OPENWEATHER_API_KEY:
        required: true
      MONGODB_CONNECTION_STRING: # Changed to MONGODB_CONNECTION_STRING
        required: true
  push:
    branches: [ main, master ]
    paths:
      - 'src/**'
      - 'karachi_aqi_app.py'
      - 'train_karachi_models.py'
      - '.github/workflows/karachi-aqi-pipeline.yml'

jobs:
  data-collection:
    if: github.event.schedule == '0 * * * *' || (github.event_name == 'workflow_dispatch' && github.event.inputs.run_data_collection == 'true') || github.event_name == 'workflow_call'
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Set up PYTHONPATH
      run: echo "PYTHONPATH=$GITHUB_WORKSPACE" >> $GITHUB_ENV

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-ci.txt

    - name: Test secrets configuration
      env:
        OPENWEATHER_API_KEY: ${{ secrets.OPENWEATHER_API_KEY }}
        MONGODB_CONNECTION_STRING: ${{ secrets.MONGODB_CONNECTION_STRING }} # Changed to MONGODB_CONNECTION_STRING
      run: |
        python scripts/test_secret.py # This script will need to be updated to check MongoDB secrets

    - name: Run data collection
      env:
        OPENWEATHER_API_KEY: ${{ secrets.OPENWEATHER_API_KEY }}
        MONGODB_CONNECTION_STRING: ${{ secrets.MONGODB_CONNECTION_STRING }} # Changed to MONGODB_CONNECTION_STRING
      run: |
        python scripts/ci_data_collection.py

    - name: Data quality check
      env:
        MONGODB_CONNECTION_STRING: ${{ secrets.MONGODB_CONNECTION_STRING }} # Changed to MONGODB_CONNECTION_STRING
      run: |
        python -c "
        import os
        import sys
        from datetime import datetime, timedelta
        
        sys.path.append(os.getcwd()) 
        from mongodb_feature_store import MongoDBFeatureStore # Changed import

        try:
            connection_string = os.getenv('MONGODB_CONNECTION_STRING')
            if not connection_string:
                print('âŒ MONGODB_CONNECTION_STRING environment variable not set. Skipping data quality check.')
                sys.exit(1)

            store = MongoDBFeatureStore(connection_string=connection_string)
            
            if not store.collection:
                print('âŒ MongoDB connection failed. Skipping data quality check.')
                sys.exit(1)

            stats = store.get_statistics()

            print(f'ðŸ“Š Data quality check:')
            if 'error' in stats:
                print('âŒ Error retrieving MongoDB statistics: {}'.format(stats['error']))
                sys.exit(1)

            total_records = stats.get('total_records', 0)
            date_range = stats.get('date_range', {})
            last_updated_str = date_range.get('end')
            recent_records_count = 0

            if last_updated_str:
                if isinstance(last_updated_str, datetime):
                    last_updated_dt = last_updated_str
                else:
                    last_updated_dt = datetime.fromisoformat(last_updated_str.replace('Z', '+00:00') if 'Z' in last_updated_str else last_updated_str)
            
            if last_updated_dt:
                recent_data_df = store.get_recent_data(hours=1)
                recent_records_count = len(recent_data_df)

            print(f'   Total records in MongoDB: {total_records}')
            print(f'   Recent records (last hour): {recent_records_count}')
            print('   Data range: {} to {}'.format(date_range.get('start'), date_range.get('end')))

            if recent_records_count == 0:
                print('âš ï¸  Warning: No data collected in the last hour in MongoDB')
                sys.exit(1)

            print('âœ… Data quality check passed for MongoDB')

        except Exception as e:
            print(f'âŒ Failed to perform MongoDB data quality check: {e}')
            sys.exit(1)
        "

  model-training:
    if: github.event.schedule == '0 2 * * *' || (github.event_name == 'workflow_dispatch' && github.event.inputs.run_model_training == 'true') || github.event.name == 'workflow_call'
    runs-on: ubuntu-latest
    needs: data-collection

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Set up PYTHONPATH
      run: echo "PYTHONPATH=$GITHUB_WORKSPACE" >> $GITHUB_ENV

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-ci.txt

    - name: Check if training is needed
      id: check_training
      run: |
        python -c "
        import os
        from pathlib import Path
        import time
        import sys
        
        sys.path.append(os.getcwd()) 

        models_dir = Path('src/models/saved_models')
        needs_training = 'true'

        event_name = os.getenv('GITHUB_EVENT_NAME', '')
        if event_name == 'workflow_dispatch':
            print('ðŸ¤– Manual workflow trigger detected - forcing training')
            needs_training = 'true'
        else:
            if models_dir.exists():
                current_time = time.time()
                recent_models = False

                for model_file in models_dir.glob('*karachi*.joblib'):
                    age_hours = (current_time - model_file.stat().st_mtime) / 3600
                    print(f'ðŸ“Š Found model: {model_file.name} (age: {age_hours:.1f} hours)')
                    if age_hours < 24:
                        recent_models = True
                        break

                if recent_models:
                    needs_training = 'false'
                    print('â­ï¸  Recent models found - skipping training')
                else:
                    print('ðŸ”„ No recent models - training needed')

        print(f'Final decision: needs_training={needs_training}')
        with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
            f.write(f'needs_training={needs_training}\n')
        "

    - name: Run model training
      if: steps.check_training.outputs.needs_training == 'true'
      env:
        MONGODB_CONNECTION_STRING: ${{ secrets.MONGODB_CONNECTION_STRING }} # Changed to MONGODB_CONNECTION_STRING
      run: |
        python scripts/ci_model_training.py

    - name: Evaluate model performance
      if: steps.check_training.outputs.needs_training == 'true'
      run: |
        python -c "
        import os
        import json
        from pathlib import Path

        models_dir = Path('src/models/saved_models')
        perf_files = list(models_dir.glob('performance*karachi*.json'))

        if perf_files:
            latest_perf = max(perf_files, key=lambda x: x.stat().st_mtime)

            with open(latest_perf, 'r') as f:
                performance = json.load(f)

            print('ðŸ¤– Model Performance Results:')
            for model_name, metrics in performance.items():
                if isinstance(metrics, dict) and 'test_r2' in metrics:
                    r2_score = metrics['test_r2']
                    mae = metrics.get('test_mae', 'N/A')
                    print(f'   {model_name}: RÂ² = {r2_score:.3f}, MAE = {mae}')

                    if model_name == 'random_forest':
                        print(f'   ðŸ† Best model: {model_name} (RÂ² = {r2_score:.3f})')
        else:
            print('âŒ No performance files found')
        "

    - name: Upload model artifacts
      if: steps.check_training.outputs.needs_training == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: trained-models
        path: |
          src/models/saved_models/*karachi*.joblib
          src/models/saved_models/*karachi*.json
        retention-days: 30

  deploy:
    if: github.event.schedule == '0 2 * * *' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    needs: [data-collection, model-training]

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Deploy notification
      env:
        MONGODB_CONNECTION_STRING: ${{ secrets.MONGODB_CONNECTION_STRING }} # Changed to MONGODB_CONNECTION_STRING
      run: |
        echo "ðŸ“Š Pipeline Status Report:"
        echo ""

        if [ "${{ needs.data-collection.result }}" == "success" ]; then
          echo "âœ… Data collection: SUCCESS (Raw data stored in MongoDB)" # Updated message
        else
          echo "âŒ Data collection: FAILED"
        fi

        echo "âœ… Feature engineering: Handled by separate workflow (Karachi AQI Feature Pipeline)"

        if [ "${{ needs.model-training.result }}" == "success" ]; then
          echo "âœ… Model training: SUCCESS"
          echo "ðŸš€ Models ready for production use"
        else
          echo "âŒ Model training: FAILED"
          echo "ðŸ”§ Check model training logs for details"
        fi

        echo ""
        if [ "${{ needs.data-collection.result }}" == "success" ] && [ "${{ needs.model-training.result }}" == "success" ]; then
          echo "ðŸŽ‰ Karachi AQI Pipeline: COMPLETE SUCCESS!"
        else
          echo "âš ï¸ Karachi AQI Pipeline: COMPLETED WITH ISSUES"
          echo "ðŸ“ Pipeline will retry on next scheduled run"
        fi
